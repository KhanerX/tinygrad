{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.multi import *\n",
    "from tinygrad import Tensor\n",
    "import numpy as np\n",
    "import tinygrad.function as F\n",
    "GPUS = (\"CUDA\", \"CLANG\")\n",
    "a = Tensor.ones((1, 2500, 2500)).shard_(GPUS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (512, 2500, 2500)\n",
    "a.requires_grad = True\n",
    "b = F.Expand.apply(a, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tinygrad.function.Expand object at 0x7e77c456b910>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA Error 2, out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/device.py:204\u001b[0m, in \u001b[0;36mLRUAllocator.alloc\u001b[0;34m(self, size, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(c \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[(size, options)]): \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mMemoryError\u001b[39;00m):\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/device.py:184\u001b[0m, in \u001b[0;36mAllocator.alloc\u001b[0;34m(self, size, options)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malloc size must be positive, getting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_alloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mBufferSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/runtime/ops_cuda.py:72\u001b[0m, in \u001b[0;36mCUDAAllocator._alloc\u001b[0;34m(self, size, options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mhost: \u001b[38;5;28;01mreturn\u001b[39;00m init_c_var(ctypes\u001b[38;5;241m.\u001b[39mc_void_p(), \u001b[38;5;28;01mlambda\u001b[39;00m x: check(cuda\u001b[38;5;241m.\u001b[39mcuMemHostAlloc(ctypes\u001b[38;5;241m.\u001b[39mbyref(x), size, \u001b[38;5;241m0x01\u001b[39m)))\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_c_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCUdeviceptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuMemAlloc_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/helpers.py:287\u001b[0m, in \u001b[0;36minit_c_var\u001b[0;34m(ctypes_var, creat_cb)\u001b[0m\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minit_c_var\u001b[39m(ctypes_var, creat_cb): \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mcreat_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes_var\u001b[49m\u001b[43m)\u001b[49m, ctypes_var)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/runtime/ops_cuda.py:72\u001b[0m, in \u001b[0;36mCUDAAllocator._alloc.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mhost: \u001b[38;5;28;01mreturn\u001b[39;00m init_c_var(ctypes\u001b[38;5;241m.\u001b[39mc_void_p(), \u001b[38;5;28;01mlambda\u001b[39;00m x: check(cuda\u001b[38;5;241m.\u001b[39mcuMemHostAlloc(ctypes\u001b[38;5;241m.\u001b[39mbyref(x), size, \u001b[38;5;241m0x01\u001b[39m)))\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m init_c_var(cuda\u001b[38;5;241m.\u001b[39mCUdeviceptr(), \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuMemAlloc_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/runtime/ops_cuda.py:13\u001b[0m, in \u001b[0;36mcheck\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(status):\n\u001b[0;32m---> 13\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctypes\u001b[38;5;241m.\u001b[39mstring_at(init_c_var(ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char)(),\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m\u001b[38;5;250m \u001b[39mx:\u001b[38;5;250m \u001b[39mcuda\u001b[38;5;241m.\u001b[39mcuGetErrorString(status,\u001b[38;5;250m \u001b[39mctypes\u001b[38;5;241m.\u001b[39mbyref(x))))\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA Error 2, out of memory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshard_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPUS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/tensor.py:973\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph)\u001b[0m\n\u001b[1;32m    971\u001b[0m grads \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mbackward(t0\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mlazydata)\n\u001b[1;32m    972\u001b[0m _METADATA\u001b[38;5;241m.\u001b[39mreset(token)\n\u001b[0;32m--> 973\u001b[0m grads \u001b[38;5;241m=\u001b[39m [Tensor(g, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrealize() \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m ([grads] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mparents) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m grads)]\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mparents, grads):\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mrequires_grad:\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/tensor.py:973\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    971\u001b[0m grads \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mbackward(t0\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mlazydata)\n\u001b[1;32m    972\u001b[0m _METADATA\u001b[38;5;241m.\u001b[39mreset(token)\n\u001b[0;32m--> 973\u001b[0m grads \u001b[38;5;241m=\u001b[39m [\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m ([grads] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mparents) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m grads)]\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mparents, grads):\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mrequires_grad:\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/tensor.py:3989\u001b[0m, in \u001b[0;36m_metadata_wrapper.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3986\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3988\u001b[0m token \u001b[38;5;241m=\u001b[39m _METADATA\u001b[38;5;241m.\u001b[39mset(Metadata(name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, caller\u001b[38;5;241m=\u001b[39mcaller))\n\u001b[0;32m-> 3989\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3990\u001b[0m _METADATA\u001b[38;5;241m.\u001b[39mreset(token)\n\u001b[1;32m   3991\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/tensor.py:268\u001b[0m, in \u001b[0;36mTensor.realize\u001b[0;34m(self, do_update_stats, *lst)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrealize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mlst:Tensor, do_update_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Triggers the computation needed to create these Tensor(s).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m   \u001b[43mrun_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_with_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlst\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/engine/realize.py:168\u001b[0m, in \u001b[0;36mrun_schedule\u001b[0;34m(schedule, var_vals, do_update_stats)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ei \u001b[38;5;129;01min\u001b[39;00m lower_schedule(schedule):\n\u001b[1;32m    167\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(capturing) \u001b[38;5;129;01mand\u001b[39;00m CAPTURING: capturing[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39madd(ei)\n\u001b[0;32m--> 168\u001b[0m   \u001b[43mei\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_update_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_update_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/engine/realize.py:123\u001b[0m, in \u001b[0;36mExecItem.run\u001b[0;34m(self, _var_vals, wait, jit, do_update_stats)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, _var_vals:Optional[\u001b[38;5;28mdict\u001b[39m[Variable, \u001b[38;5;28mint\u001b[39m]]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, jit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, do_update_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    122\u001b[0m   var_vals \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m _var_vals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _var_vals\n\u001b[0;32m--> 123\u001b[0m   bufs \u001b[38;5;241m=\u001b[39m [cast(Buffer, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbufs] \u001b[38;5;28;01mif\u001b[39;00m jit \u001b[38;5;28;01melse\u001b[39;00m [cast(Buffer, x)\u001b[38;5;241m.\u001b[39mensure_allocated() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbufs]\n\u001b[1;32m    124\u001b[0m   et \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprg(bufs, var_vals, wait\u001b[38;5;241m=\u001b[39mwait \u001b[38;5;129;01mor\u001b[39;00m DEBUG \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m do_update_stats:\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/engine/realize.py:123\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, _var_vals:Optional[\u001b[38;5;28mdict\u001b[39m[Variable, \u001b[38;5;28mint\u001b[39m]]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, jit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, do_update_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    122\u001b[0m   var_vals \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m _var_vals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _var_vals\n\u001b[0;32m--> 123\u001b[0m   bufs \u001b[38;5;241m=\u001b[39m [cast(Buffer, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbufs] \u001b[38;5;28;01mif\u001b[39;00m jit \u001b[38;5;28;01melse\u001b[39;00m [\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_allocated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbufs]\n\u001b[1;32m    124\u001b[0m   et \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprg(bufs, var_vals, wait\u001b[38;5;241m=\u001b[39mwait \u001b[38;5;129;01mor\u001b[39;00m DEBUG \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m do_update_stats:\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/device.py:111\u001b[0m, in \u001b[0;36mBuffer.ensure_allocated\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mensure_allocated\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Buffer: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_allocated() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/device.py:122\u001b[0m, in \u001b[0;36mBuffer.allocate\u001b[0;34m(self, opaque, external_ptr)\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buf: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallocator\u001b[38;5;241m.\u001b[39m_offset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39m_buf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnbytes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buf \u001b[38;5;241m=\u001b[39m opaque \u001b[38;5;28;01mif\u001b[39;00m opaque \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malloc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDISK\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHON\u001b[39m\u001b[38;5;124m\"\u001b[39m)): \n\u001b[1;32m    124\u001b[0m     GlobalCounters\u001b[38;5;241m.\u001b[39mmem_used \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnbytes\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/device.py:207\u001b[0m, in \u001b[0;36mLRUAllocator.alloc\u001b[0;34m(self, size, options)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mMemoryError\u001b[39;00m):\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_cache()\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/device.py:184\u001b[0m, in \u001b[0;36mAllocator.alloc\u001b[0;34m(self, size, options)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21malloc\u001b[39m(\u001b[38;5;28mself\u001b[39m, size:\u001b[38;5;28mint\u001b[39m, options:Optional[BufferSpec]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malloc size must be positive, getting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 184\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_alloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mBufferSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/runtime/ops_cuda.py:72\u001b[0m, in \u001b[0;36mCUDAAllocator._alloc\u001b[0;34m(self, size, options)\u001b[0m\n\u001b[1;32m     70\u001b[0m check(cuda\u001b[38;5;241m.\u001b[39mcuCtxSetCurrent(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev\u001b[38;5;241m.\u001b[39mcontext))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mhost: \u001b[38;5;28;01mreturn\u001b[39;00m init_c_var(ctypes\u001b[38;5;241m.\u001b[39mc_void_p(), \u001b[38;5;28;01mlambda\u001b[39;00m x: check(cuda\u001b[38;5;241m.\u001b[39mcuMemHostAlloc(ctypes\u001b[38;5;241m.\u001b[39mbyref(x), size, \u001b[38;5;241m0x01\u001b[39m)))\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_c_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCUdeviceptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuMemAlloc_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/helpers.py:287\u001b[0m, in \u001b[0;36minit_c_var\u001b[0;34m(ctypes_var, creat_cb)\u001b[0m\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minit_c_var\u001b[39m(ctypes_var, creat_cb): \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mcreat_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes_var\u001b[49m\u001b[43m)\u001b[49m, ctypes_var)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/runtime/ops_cuda.py:72\u001b[0m, in \u001b[0;36mCUDAAllocator._alloc.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     70\u001b[0m check(cuda\u001b[38;5;241m.\u001b[39mcuCtxSetCurrent(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev\u001b[38;5;241m.\u001b[39mcontext))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mhost: \u001b[38;5;28;01mreturn\u001b[39;00m init_c_var(ctypes\u001b[38;5;241m.\u001b[39mc_void_p(), \u001b[38;5;28;01mlambda\u001b[39;00m x: check(cuda\u001b[38;5;241m.\u001b[39mcuMemHostAlloc(ctypes\u001b[38;5;241m.\u001b[39mbyref(x), size, \u001b[38;5;241m0x01\u001b[39m)))\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m init_c_var(cuda\u001b[38;5;241m.\u001b[39mCUdeviceptr(), \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuMemAlloc_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/tinygrad/tinygrad/runtime/ops_cuda.py:13\u001b[0m, in \u001b[0;36mcheck\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(status):\n\u001b[0;32m---> 13\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctypes\u001b[38;5;241m.\u001b[39mstring_at(init_c_var(ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char)(),\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m\u001b[38;5;250m \u001b[39mx:\u001b[38;5;250m \u001b[39mcuda\u001b[38;5;241m.\u001b[39mcuGetErrorString(status,\u001b[38;5;250m \u001b[39mctypes\u001b[38;5;241m.\u001b[39mbyref(x))))\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA Error 2, out of memory"
     ]
    }
   ],
   "source": [
    "b.backward(Tensor.ones(shape).shard_(GPUS, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor <MLB self.axis=1 self.real=[True, True] \n",
       "CLANG ShapeTracker(views=(View(shape=(512, 1250, 2500), strides=(3125000, 2500, 1), offset=0, mask=None, contiguous=True),))\n",
       "CLANG ShapeTracker(views=(View(shape=(512, 1250, 2500), strides=(3125000, 2500, 1), offset=0, mask=None, contiguous=True),))> on ('CLANG', 'CLANG') with grad None>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad.realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
